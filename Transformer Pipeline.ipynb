{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tf-models-official==2.5.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (2.5.0)\n",
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (4.6.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-models-official==2.5.0) (3.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (5.4.1)\n",
      "Requirement already satisfied: tensorflow>=2.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-models-official==2.5.0) (2.9.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-models-official==2.5.0) (1.4.2)\n",
      "Requirement already satisfied: pycocotools in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-models-official==2.5.0) (2.0.4)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (1.5.12)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (4.6.0.66)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (2.52.0)\n",
      "Requirement already satisfied: psutil>=5.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-models-official==2.5.0) (5.8.0)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (8.0.0)\n",
      "Requirement already satisfied: Cython in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-models-official==2.5.0) (0.29.28)\n",
      "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (3.2.0)\n",
      "Requirement already satisfied: gin-config in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (0.5.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (0.12.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (0.1.96)\n",
      "Requirement already satisfied: seqeval in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (1.2.2)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-models-official==2.5.0) (1.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-models-official==2.5.0) (1.7.3)\n",
      "Requirement already satisfied: oauth2client in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (4.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-models-official==2.5.0) (1.21.5)\n",
      "Requirement already satisfied: sacrebleu in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-addons in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (0.17.1)\n",
      "Requirement already satisfied: tf-slim>=1.1.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tf-models-official==2.5.0) (0.7.2)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-models-official==2.5.0) (9.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.5.0) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.5.0) (4.1.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.5.0) (2.8.2)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.5.0) (0.20.4)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.5.0) (1.33.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (1.56.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (2.27.1)\n",
      "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (3.19.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (4.7.2)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (61.2.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.5.0) (1.20.6)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.5.0) (2.3.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.5.0) (1.3.1)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.0.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.5.0) (2.13.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.38.1 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.5.0) (1.47.0)\n",
      "Requirement already satisfied: pyarrow<9.0dev,>=3.0.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.5.0) (8.0.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.5.0) (2.8.2)\n",
      "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.5.0) (21.3)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (1.47.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official==2.5.0) (1.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cffi>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official==2.5.0) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official==2.5.0) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (3.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official==2.5.0) (4.64.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official==2.5.0) (2021.10.8)\n",
      "Requirement already satisfied: python-slugify in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official==2.5.0) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official==2.5.0) (1.26.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.22.0->tf-models-official==2.5.0) (2021.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.5.0) (3.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (0.26.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (14.0.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (2.9.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (2.9.1)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (3.6.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (4.1.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.5.0->tf-models-official==2.5.0) (1.12)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.5.0->tf-models-official==2.5.0) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.5.0->tf-models-official==2.5.0) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.5.0->tf-models-official==2.5.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.5.0->tf-models-official==2.5.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.5.0->tf-models-official==2.5.0) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.5.0->tf-models-official==2.5.0) (3.3.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.5.0->tf-models-official==2.5.0) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.5.0->tf-models-official==2.5.0) (3.2.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.5.0) (0.1.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->tf-models-official==2.5.0) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->tf-models-official==2.5.0) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->tf-models-official==2.5.0) (4.25.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.5.0) (1.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from sacrebleu->tf-models-official==2.5.0) (0.4.4)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from sacrebleu->tf-models-official==2.5.0) (2022.3.15)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from sacrebleu->tf-models-official==2.5.0) (0.8.9)\n",
      "Requirement already satisfied: portalocker in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from sacrebleu->tf-models-official==2.5.0) (2.4.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\programdata\\anaconda3\\lib\\site-packages (from portalocker->sacrebleu->tf-models-official==2.5.0) (302)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from seqeval->tf-models-official==2.5.0) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.5.0) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.5.0) (2.2.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-addons->tf-models-official==2.5.0) (2.13.3)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets->tf-models-official==2.5.0) (1.9.0)\n",
      "Requirement already satisfied: etils[epath] in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets->tf-models-official==2.5.0) (0.6.0)\n",
      "Requirement already satisfied: promise in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets->tf-models-official==2.5.0) (2.3)\n",
      "Requirement already satisfied: dill in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets->tf-models-official==2.5.0) (0.3.5.1)\n",
      "Requirement already satisfied: toml in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-datasets->tf-models-official==2.5.0) (0.10.2)\n",
      "Requirement already satisfied: zipp in c:\\programdata\\anaconda3\\lib\\site-packages (from etils[epath]->tensorflow-datasets->tf-models-official==2.5.0) (3.7.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\haris.medjahed\\appdata\\roaming\\python\\python39\\site-packages (from etils[epath]->tensorflow-datasets->tf-models-official==2.5.0) (5.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-models-official==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_text as tf_text\n",
    "from official.nlp.transformer.utils import tokenizer as tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from official.nlp.transformer import metrics, embedding_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.nlp.transformer import transformer_main, model_params\n",
    "from official.utils.misc import distribution_utils\n",
    "from official.nlp.transformer import transformer\n",
    "from official.nlp.transformer import optimizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"data/\"\n",
    "path_model = \"../../../tensorboard_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_TYPES =  [0]+ [0] + ['a']+['a']\n",
    "DEFAULTS = [tf.int64, tf.int64, tf.int64 ,tf.int64]\n",
    "COL_NAMES = [\"DocID\",\"LineID\",\"RawText\",\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGE_CUT_VALUES = np.concatenate([[-2, -1, 1], (5 + np.arange(0, 125, 5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire attention à ne pas enlever toutes les points d'exclamationsqui peuvent représenter des mots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "  # Split accecented characters.\n",
    "  #import unidecode\n",
    "  #text = unidecode.unidecode(text)\n",
    "  text = tf.strings.lower(text)\n",
    "  # Keep space, a to z, and select punctuation.\n",
    "  text = tf.strings.regex_replace(text, '^ a-z.!?,¿', '')\n",
    "  # Add spaces around punctuation.\n",
    "  text = tf.strings.regex_replace(text, '.?!,¿', r' \\0 ')\n",
    "  # Strip whitespace.\n",
    "  text = tf.strings.strip(text)\n",
    "\n",
    "  text = tf.strings.join(['[START]', text, '[END] '], separator=' ')\n",
    "  return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_processor = preprocessing.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=None)\n",
    "\n",
    "target_processor = preprocessing.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_text_processor.adapt(dataset)\n",
    "# take very long time, different way for the moment\n",
    "data = pd.read_csv(\"data/corpus_train_code_target.csv\", encoding='utf-8', sep=\";\")\n",
    "input_text_processor.adapt(data.RawText)\n",
    "target_processor.adapt(data.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_text_processor.adapt(df.ADAPT)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump({'config': input_text_processor.get_config(),\n",
    "             'weights': input_text_processor.get_weights()}\n",
    "            , open(\"full_adapt_processor.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump({'config': input_text_processor.get_config(),\n",
    "             'weights': input_text_processor.get_weights()}\n",
    "            , open(\"full_adapt_processor.pkl\", \"wb\"))\n",
    "pickle.dump({'config': target_processor.get_config(),\n",
    "             'weights': target_processor.get_weights()}\n",
    "            , open(\"full_target_processor.pkl\", \"wb\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136158"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_text_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20861"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " '[START]',\n",
       " '[END]',\n",
       " '[sepcode]',\n",
       " 'arret',\n",
       " 'insuffisance',\n",
       " 'cardio-respiratoire',\n",
       " 'cardiaque',\n",
       " 'respiratoire',\n",
       " 'cancer',\n",
       " 'pneumopathie',\n",
       " 'choc',\n",
       " 'pulmonaire',\n",
       " 'aigue',\n",
       " 'defaillance',\n",
       " 'metastases',\n",
       " 'renale',\n",
       " 'syndrome',\n",
       " 'etat',\n",
       " 'terminale',\n",
       " 'detresse',\n",
       " 'avc',\n",
       " 'cardiopathie',\n",
       " 'demence',\n",
       " 'severe',\n",
       " 'ischemique',\n",
       " 'septique',\n",
       " 'chronique',\n",
       " 'decompensation',\n",
       " 'maladie',\n",
       " 'multiviscerale',\n",
       " 'alzheimer',\n",
       " 'hta',\n",
       " 'neoplasie',\n",
       " 'metastatique',\n",
       " '!',\n",
       " 'coma',\n",
       " 'carcinome',\n",
       " 'inhalation',\n",
       " 'mort',\n",
       " 'adenocarcinome',\n",
       " 'bronchique',\n",
       " 'troubles',\n",
       " 'hemorragie',\n",
       " 'infarctus',\n",
       " 'denutrition',\n",
       " 'metastase',\n",
       " 'diabete',\n",
       " 'alteration',\n",
       " 'general',\n",
       " 'cerebral',\n",
       " 'hepatique',\n",
       " 'acr',\n",
       " 'infection',\n",
       " 'stade',\n",
       " 'vasculaire',\n",
       " 'gauche',\n",
       " 'sepsis',\n",
       " '|',\n",
       " 'cirrhose',\n",
       " 'cachexie',\n",
       " 'embolie',\n",
       " 'probable',\n",
       " 'sein',\n",
       " 'neo',\n",
       " 'bpco',\n",
       " 'grabataire',\n",
       " 'accident',\n",
       " 'evolution',\n",
       " 'hemorragique',\n",
       " 'glissement',\n",
       " 'myocarde',\n",
       " 'de',\n",
       " 'hepatiques',\n",
       " 'tumeur',\n",
       " 'cerebrale',\n",
       " 'digestive',\n",
       " 'subite',\n",
       " 'rythme',\n",
       " 'soins',\n",
       " 'trouble',\n",
       " 'carcinose',\n",
       " 'evoluee',\n",
       " 'peritoneale',\n",
       " 'terminal',\n",
       " 'pancreas',\n",
       " 'deshydratation',\n",
       " 'colique',\n",
       " 'fracture',\n",
       " 'poumon',\n",
       " 'cardiogenique',\n",
       " 'palliatifs',\n",
       " 'cardio-circulatoire',\n",
       " 'type',\n",
       " 'massif',\n",
       " 'ischemie',\n",
       " 'droit',\n",
       " 'prostate',\n",
       " 'hematome',\n",
       " 'aortique',\n",
       " 'deglutition',\n",
       " 'aigu',\n",
       " 'chute',\n",
       " 'cardio-vasculaire',\n",
       " 'fin',\n",
       " 'surinfection',\n",
       " 'parkinson',\n",
       " 'age',\n",
       " 'pulmonaires',\n",
       " 'oap',\n",
       " 'vie',\n",
       " 'hta,',\n",
       " 'grabatisation',\n",
       " 'encephalopathie',\n",
       " 'droite',\n",
       " 'osseuses',\n",
       " 'fibrillation',\n",
       " 'phase',\n",
       " 'leucemie',\n",
       " 'acfa',\n",
       " 'anemie',\n",
       " 'traumatisme',\n",
       " 'septicemie',\n",
       " 'cerebrales',\n",
       " 'globale',\n",
       " 'occlusion',\n",
       " 'multimetastatique',\n",
       " 'hypertension',\n",
       " 'lymphome',\n",
       " 'aeg',\n",
       " 'idm',\n",
       " 'epidermoide',\n",
       " 'colon',\n",
       " 'naturelle',\n",
       " 'massive',\n",
       " 'du',\n",
       " 'non',\n",
       " 'encombrement',\n",
       " 'pendaison',\n",
       " 'fausse',\n",
       " 'route',\n",
       " 'vessie',\n",
       " 'multiples',\n",
       " 'ac/fa',\n",
       " 'refractaire',\n",
       " 'bronchopneumopathie',\n",
       " 'urinaire',\n",
       " 'hypoxemiante',\n",
       " 'oedeme',\n",
       " 'sous',\n",
       " 'polyviscerale',\n",
       " 'et',\n",
       " 'hepatocellulaire',\n",
       " 'cranien',\n",
       " 'cardiaque,',\n",
       " 'col',\n",
       " 'bilaterale',\n",
       " 'infectieuse',\n",
       " 'broncho-pulmonaire',\n",
       " 'rupture',\n",
       " 'auriculaire',\n",
       " '2',\n",
       " 'mesenterique',\n",
       " 'gastrique',\n",
       " '?',\n",
       " 'suicide',\n",
       " 'hypertensive',\n",
       " 'avec',\n",
       " 'grand',\n",
       " 'par',\n",
       " 'inferieur',\n",
       " 'occlusif',\n",
       " 'cellules',\n",
       " 'arterielle',\n",
       " 'fa',\n",
       " 'arteriopathie',\n",
       " 'cognitifs',\n",
       " 'coronaropathie',\n",
       " 'sylvien',\n",
       " 'peritonite',\n",
       " 'ventriculaire',\n",
       " 'valvulaire',\n",
       " 'retrecissement',\n",
       " 'arterite',\n",
       " 'inconnue',\n",
       " 'grave',\n",
       " 'a',\n",
       " 'sur',\n",
       " 'pulmonaire,',\n",
       " 'cause',\n",
       " 'alcoolique',\n",
       " 'majeure',\n",
       " 'cardiomyopathie',\n",
       " 'origine',\n",
       " 'prostatique',\n",
       " 'dnid',\n",
       " 'ans',\n",
       " 'myelome',\n",
       " 'arythmie',\n",
       " 'engagement',\n",
       " 'pancreatique',\n",
       " 'obesite',\n",
       " 'tabagisme',\n",
       " 'membre',\n",
       " 'recidive',\n",
       " 'depressif',\n",
       " 'rythmique',\n",
       " 'membres',\n",
       " 'foie',\n",
       " 'glioblastome',\n",
       " 'ischemique,',\n",
       " 'pleural',\n",
       " 'mixte',\n",
       " 'hypoxie',\n",
       " 'femur',\n",
       " 'coronarien',\n",
       " 'indeterminee',\n",
       " 'orl',\n",
       " 'anevrisme',\n",
       " 'serre',\n",
       " 'dementiel',\n",
       " 'hemiplegie',\n",
       " 'en',\n",
       " 'fibrose',\n",
       " 'escarres',\n",
       " 'rein',\n",
       " 'anorexie',\n",
       " 'hypoxique',\n",
       " 'encephalique',\n",
       " 'sous-dural',\n",
       " 'repetition',\n",
       " 'asystolie',\n",
       " 'mammaire',\n",
       " 'ethylique',\n",
       " 'petites',\n",
       " 'malaise',\n",
       " 'cholangiocarcinome',\n",
       " 'inferieurs',\n",
       " 'epanchement',\n",
       " 'avk',\n",
       " 'ethylisme',\n",
       " 'evolue',\n",
       " 'thrombose',\n",
       " 'depression',\n",
       " 'envahissement',\n",
       " 'intestinale',\n",
       " 'infectieux',\n",
       " 'melanome',\n",
       " 'cardiorespiratoire',\n",
       " 'pneumonie',\n",
       " 'dilatee',\n",
       " 'epilepsie',\n",
       " 'post-operatoire',\n",
       " 'aomi',\n",
       " 'severe,',\n",
       " 'oesophage',\n",
       " 'tres',\n",
       " 'deces',\n",
       " 'brutal',\n",
       " 'bronchite',\n",
       " 'terminale,',\n",
       " 'polymetastatique',\n",
       " 'deme',\n",
       " 'corps',\n",
       " 'rectum',\n",
       " 'hepatite',\n",
       " 'mal',\n",
       " 'carcinomateuse',\n",
       " 'meta',\n",
       " 'refus',\n",
       " 'chimiotherapie',\n",
       " 'aorte',\n",
       " 'circulatoire',\n",
       " '4',\n",
       " 'k',\n",
       " 'chirurgie',\n",
       " 'ss',\n",
       " 'chronique,',\n",
       " 'sequelles',\n",
       " 'palliative',\n",
       " 'escarre',\n",
       " 'thoracique',\n",
       " 'alcoolisme',\n",
       " 'intoxication',\n",
       " 'fausses',\n",
       " 'cardio',\n",
       " 'prothese',\n",
       " 'tronc',\n",
       " 'senile',\n",
       " 'decompensee',\n",
       " '!,',\n",
       " 'necrose',\n",
       " 'myocardiopathie',\n",
       " 'routes',\n",
       " 'perforation',\n",
       " 'asphyxie',\n",
       " 'pyelonephrite',\n",
       " 'progressive',\n",
       " 'abdominale',\n",
       " 'dyspnee',\n",
       " 'coronarienne',\n",
       " 'myocardique',\n",
       " 'generalise',\n",
       " 'ulcere',\n",
       " 'c',\n",
       " 'diabete,',\n",
       " 'multimetastase',\n",
       " 'maligne',\n",
       " 'endocardite',\n",
       " 'ascite',\n",
       " 'denutrition,',\n",
       " 'traitement',\n",
       " 'i',\n",
       " 'primitif',\n",
       " 'sd',\n",
       " 'b',\n",
       " 'hepatiques,',\n",
       " 'pontage',\n",
       " 'depuis',\n",
       " 'polytraumatisme',\n",
       " 'opere',\n",
       " 'hypercapnique',\n",
       " 'vieillesse',\n",
       " 'progression',\n",
       " 'obstructive',\n",
       " 'pathologie',\n",
       " 'aplasie',\n",
       " 'epileptique',\n",
       " 'hepatocarcinome',\n",
       " 'alimentaire',\n",
       " 'g',\n",
       " 'mitrale',\n",
       " 'neoplasme',\n",
       " 'contexte',\n",
       " 'multiple',\n",
       " 'acidose',\n",
       " 'hanche',\n",
       " 'collapsus',\n",
       " 'sclerose',\n",
       " 'dans',\n",
       " 'hyperkaliemie',\n",
       " 'pancreatite',\n",
       " 'urothelial',\n",
       " '1',\n",
       " 'pleuresie',\n",
       " 'degradation',\n",
       " 'plaie',\n",
       " 'renale,',\n",
       " 'ovaire',\n",
       " 'femoral',\n",
       " 'atcd',\n",
       " 'avc,',\n",
       " 'perte',\n",
       " 'bpco,',\n",
       " 'staphylocoque',\n",
       " 'sdra',\n",
       " 'vomissements',\n",
       " 'avp',\n",
       " 'mois',\n",
       " ',',\n",
       " 'dialyse',\n",
       " 'myeloide',\n",
       " 'lewy',\n",
       " 'la',\n",
       " 'arme',\n",
       " 'meningite',\n",
       " 'medullaire',\n",
       " 'stenose',\n",
       " '3',\n",
       " 'cachectique',\n",
       " 'alzheimer,',\n",
       " 'asthme',\n",
       " 'hypovolemique',\n",
       " 'prise',\n",
       " 'meningee',\n",
       " 'respiratoire,',\n",
       " 'osseuse',\n",
       " 'neoplasique',\n",
       " 'post-anoxique',\n",
       " 'domicile',\n",
       " 'noyade',\n",
       " 'surdosage',\n",
       " 'iv',\n",
       " 'palliatif',\n",
       " 'therapeutique',\n",
       " 'profonde',\n",
       " 'sommeil',\n",
       " 'fistule',\n",
       " 'insulino-dependant',\n",
       " 'grabataire,',\n",
       " 'bronchique,',\n",
       " 'valvulopathie',\n",
       " 'digestif',\n",
       " 'sein,',\n",
       " 'physiologique',\n",
       " 'feu',\n",
       " 'voie',\n",
       " 'metastasee',\n",
       " 'diabetique',\n",
       " 'ovarien',\n",
       " 'metabolique',\n",
       " 'intracranienne',\n",
       " 'ganglionnaires',\n",
       " 'epuisement',\n",
       " 'anoxie',\n",
       " 'bas',\n",
       " 'uterin',\n",
       " 'abces',\n",
       " 'myelodysplasie',\n",
       " 'inconnu',\n",
       " 'crise',\n",
       " 'hypothyroidie',\n",
       " 'ep',\n",
       " 'estomac',\n",
       " 'amputation',\n",
       " 'antecedent',\n",
       " 'recupere',\n",
       " 'dissection',\n",
       " 'demence,',\n",
       " 'did',\n",
       " 'coronaire',\n",
       " 'retrouve',\n",
       " 'psychose',\n",
       " 'polypathologie',\n",
       " 'point',\n",
       " 'secondaire',\n",
       " 'mi',\n",
       " 'hypoxemie',\n",
       " 'pacemaker',\n",
       " 'patient',\n",
       " 'compression',\n",
       " 'ac/fa,',\n",
       " 'colite',\n",
       " 'hepatique,',\n",
       " 'douleur',\n",
       " 'avance',\n",
       " 'angiocholite',\n",
       " 'diffuse',\n",
       " 'prostate,',\n",
       " 'lymphangite',\n",
       " 'voies',\n",
       " 'insulino-requerant',\n",
       " 'mecanique',\n",
       " 'hemoptysie',\n",
       " 'depart',\n",
       " 'renal',\n",
       " 'dyslipidemie',\n",
       " 'malin',\n",
       " 'post',\n",
       " 'biliaire',\n",
       " 'certificat',\n",
       " 'bav',\n",
       " 'suspicion',\n",
       " 'evolutif',\n",
       " 'grele',\n",
       " 'morbide',\n",
       " 'hematemese',\n",
       " 'pulmonaires,',\n",
       " 'tabac',\n",
       " 'charge',\n",
       " 'colique,',\n",
       " 'htap',\n",
       " 'atteinte',\n",
       " 'thrombopenie',\n",
       " 'vierge',\n",
       " 'sophage',\n",
       " 'poussee',\n",
       " 'arraat',\n",
       " 'jours',\n",
       " 'osseuses,',\n",
       " 'mesotheliome',\n",
       " 'alimentation',\n",
       " 'laterale',\n",
       " 'publique',\n",
       " 'neurologique',\n",
       " 'jambe',\n",
       " 'haute',\n",
       " 'sarcome',\n",
       " 'amyotrophique',\n",
       " 'os',\n",
       " 'rectal',\n",
       " 'patiente',\n",
       " 'evolutive',\n",
       " 'anasarque',\n",
       " 'tete',\n",
       " 'lymphoide',\n",
       " 'complications',\n",
       " 'etendu',\n",
       " 'general,',\n",
       " 'sigmoide',\n",
       " 'adk',\n",
       " 'valve',\n",
       " 'chutes',\n",
       " 'conscience',\n",
       " 'terrain',\n",
       " 'cachexie,',\n",
       " 'majeur',\n",
       " 'polyvasculaire',\n",
       " 'grade',\n",
       " 'tumorale',\n",
       " 'acfa,',\n",
       " 'varices',\n",
       " 'alitement',\n",
       " 'phlebite',\n",
       " 'bacterienne',\n",
       " 'gangrene',\n",
       " 'grandes',\n",
       " 'aigue,',\n",
       " 'autonomie',\n",
       " 'hernie',\n",
       " 'ii',\n",
       " 'pancreas,',\n",
       " 'intracerebrale',\n",
       " 'diffuses',\n",
       " 'endometre',\n",
       " 'langue',\n",
       " 'uterus',\n",
       " 'febrile',\n",
       " 'kc',\n",
       " 'anevrysme',\n",
       " 'post-tabagique',\n",
       " 'anoxique',\n",
       " 'etiologie',\n",
       " 'lesions',\n",
       " 'operee',\n",
       " 'emphyseme',\n",
       " 'paroxystique',\n",
       " 'cholecystite',\n",
       " 'totale',\n",
       " 'vesicale',\n",
       " 'superieur',\n",
       " 'anterieur',\n",
       " 'oh',\n",
       " 'ganglionnaire',\n",
       " 'metastatique,',\n",
       " 'cardio-pulmonaire',\n",
       " 'bilateral',\n",
       " 'pied',\n",
       " 'polymetastase',\n",
       " 'dnid,',\n",
       " 'base',\n",
       " 'chez',\n",
       " 'hepato-cellulaire',\n",
       " \"d'inhalation\",\n",
       " 'nosocomiale',\n",
       " '+',\n",
       " 'hypercalcemie',\n",
       " 'multi-viscerale',\n",
       " 'hepatorenal',\n",
       " 'generalisee',\n",
       " 'gauche,',\n",
       " 'peritoneales',\n",
       " 'myeloblastique',\n",
       " 'grabaterisation',\n",
       " 'medicamenteuse',\n",
       " 'debit',\n",
       " 'bronchopulmonaire',\n",
       " 'possible',\n",
       " 'diarrhee',\n",
       " 'masse',\n",
       " 'stent',\n",
       " 'sans',\n",
       " 'sca',\n",
       " 'ins',\n",
       " 'remplacement',\n",
       " 'd',\n",
       " '10',\n",
       " 'suite',\n",
       " 'obliterante',\n",
       " 'deshydratation,',\n",
       " 'pneumocoque',\n",
       " 'pleurales',\n",
       " 'liquide',\n",
       " 'anticoagulant',\n",
       " 'trauma',\n",
       " 'clostridium',\n",
       " 'abdominal',\n",
       " 'decede',\n",
       " 'cours',\n",
       " 'intracerebral',\n",
       " 'polyarthrite',\n",
       " 'rhabdomyolyse',\n",
       " 'complete',\n",
       " 'dialysee',\n",
       " 'veineuse',\n",
       " 'pth',\n",
       " 'oedemato-ascitique',\n",
       " 'haut',\n",
       " 'avancee',\n",
       " 'des',\n",
       " 'rac',\n",
       " 'senescence',\n",
       " 'larynx',\n",
       " 'hypokinetique',\n",
       " 'diffus',\n",
       " 'lesion',\n",
       " 'hypertrophique',\n",
       " 'echappement',\n",
       " 'dissociation',\n",
       " '-',\n",
       " 'interne',\n",
       " 'terminal,',\n",
       " 'comportement',\n",
       " 'cardia',\n",
       " 'septique,',\n",
       " 'chute,',\n",
       " 'greffe',\n",
       " 'ou',\n",
       " 'fonctions',\n",
       " 'senilite',\n",
       " 'degenerative',\n",
       " 'ans,',\n",
       " 'infiltrant',\n",
       " 'grippe',\n",
       " 'angor',\n",
       " 'extreme',\n",
       " 'bacteriemie',\n",
       " 'child',\n",
       " 'rao',\n",
       " 'bradycardie',\n",
       " 'decubitus',\n",
       " 'irc',\n",
       " 'aeg,',\n",
       " 'coli',\n",
       " 'radiotherapie',\n",
       " 'vesical',\n",
       " 'poumon,',\n",
       " 'profond',\n",
       " 'artere',\n",
       " 'pneumopathie,',\n",
       " 'sacree',\n",
       " 'restrictive',\n",
       " 'secondaires',\n",
       " 'colon,',\n",
       " '5',\n",
       " 'evoluee,',\n",
       " 'prolonge',\n",
       " 'tachycardie',\n",
       " 'decouverte',\n",
       " 'biliaires',\n",
       " 'son',\n",
       " 'severes',\n",
       " 'coeur',\n",
       " 'complication',\n",
       " 'cardio-respiratoire,',\n",
       " 'ancienne',\n",
       " 'sinus',\n",
       " 'ait',\n",
       " 'dysfonction',\n",
       " 'brutale',\n",
       " 'grabatisation,',\n",
       " 'rechute',\n",
       " 'frontal',\n",
       " 'anxio-depressif',\n",
       " 'tc',\n",
       " 'atriale',\n",
       " 'parkinson,',\n",
       " 'cerebrales,',\n",
       " 'erysipele',\n",
       " 'fa,',\n",
       " 'prematurite',\n",
       " 'pleurale',\n",
       " 'anurique',\n",
       " 'tuberculose',\n",
       " 'hemodialyse',\n",
       " 'hypertensive,',\n",
       " 'neuroendocrine',\n",
       " 'vessie,',\n",
       " 'pancytopenie',\n",
       " 'ovarienne',\n",
       " 'ictere',\n",
       " 'lobaire',\n",
       " 'traumatique',\n",
       " 'carotidienne',\n",
       " 'apnee',\n",
       " 'myelodysplasique',\n",
       " 'retrouvee',\n",
       " 'colectomie',\n",
       " 'paralysie',\n",
       " 'rhumatoide',\n",
       " 'asphyxique',\n",
       " 'droit,',\n",
       " 'osteite',\n",
       " 'alcool',\n",
       " 'meningiome',\n",
       " 'rapide',\n",
       " 'respiratoires',\n",
       " 'cervicale',\n",
       " 'civd',\n",
       " 'exogenose',\n",
       " 'au',\n",
       " 'complique',\n",
       " 'basse',\n",
       " 'oesophagienne',\n",
       " 'viscerale',\n",
       " 'virale',\n",
       " 'tamponnade',\n",
       " 'hodgkinien',\n",
       " 'dt',\n",
       " 'dilatation',\n",
       " 'seul',\n",
       " 'irreversible',\n",
       " 'aureus',\n",
       " 'oesophagiennes',\n",
       " 'lobe',\n",
       " '2013',\n",
       " 'parkinsonien',\n",
       " 'anurie',\n",
       " 'pendant',\n",
       " 'hypernatremie',\n",
       " 'douleurs',\n",
       " 'o2',\n",
       " 'localisations',\n",
       " 'poumons',\n",
       " 'peritoneale,',\n",
       " 'cave',\n",
       " 'colo-rectal',\n",
       " '2014',\n",
       " 'osseux',\n",
       " 'compliquee',\n",
       " 'cutanee',\n",
       " 'hydrocephalie',\n",
       " 'limitation',\n",
       " 'prostatique,',\n",
       " 'post-chimiotherapie',\n",
       " 'lit',\n",
       " 'femorale',\n",
       " 'interstitielle',\n",
       " 'broncho-pneumopathie',\n",
       " 'cutane',\n",
       " 'cerebelleux',\n",
       " 'age,',\n",
       " 'plusieurs',\n",
       " 'inondation',\n",
       " 'tabagique',\n",
       " 'llc',\n",
       " 'bassin',\n",
       " 'hypercholesterolemie',\n",
       " 'inflammatoire',\n",
       " 'b7',\n",
       " 'sequellaire',\n",
       " 'primitive',\n",
       " 'atherosclerose',\n",
       " 'bronchopathie',\n",
       " 'sonde',\n",
       " 'hypercapnie',\n",
       " 'electromecanique',\n",
       " 'obstruction',\n",
       " 'probablement',\n",
       " 'sla',\n",
       " 'vomissement',\n",
       " 'htic',\n",
       " 'vie,',\n",
       " 'aomi,',\n",
       " 'insulinodependant',\n",
       " 'difficile',\n",
       " 'sa',\n",
       " 'fractures',\n",
       " 'hypothermie',\n",
       " '->',\n",
       " 'subit',\n",
       " 'extension',\n",
       " '6',\n",
       " 'tacfa',\n",
       " 'niveau',\n",
       " 'autolyse',\n",
       " '2,',\n",
       " 'recent',\n",
       " 'glissement,',\n",
       " 'pseudomonas',\n",
       " 'vasculaires',\n",
       " 'metaboliques',\n",
       " 'pleuropneumopathie',\n",
       " 't',\n",
       " 'gastro-enterite',\n",
       " 'ancien',\n",
       " 'hemodynamique',\n",
       " 'complet',\n",
       " 'melena',\n",
       " 'neurodegenerative',\n",
       " 'canal',\n",
       " 'vasculaire,',\n",
       " 'immunodepression',\n",
       " 'inf',\n",
       " 'rectale',\n",
       " 'idiopathique',\n",
       " 'aphasie',\n",
       " 'saignement',\n",
       " 'degenerescence',\n",
       " 'obesite,',\n",
       " 'hyperosmolaire',\n",
       " 'pm',\n",
       " 'hyponatremie',\n",
       " 'amylose',\n",
       " 'foie,',\n",
       " 'vigilance',\n",
       " 'atelectasie',\n",
       " 'cognitif',\n",
       " 'ulceres',\n",
       " 'recente',\n",
       " 'post-traumatique',\n",
       " 'congestive',\n",
       " 'bloc',\n",
       " 'emblee',\n",
       " 'plaques',\n",
       " 'cervical',\n",
       " 'hypokaliemie',\n",
       " 'cerebrale,',\n",
       " 'cerebral,',\n",
       " 'importante',\n",
       " 'pas',\n",
       " 'communautaire',\n",
       " 'cardiopathie,',\n",
       " 'vitales',\n",
       " 'decedee',\n",
       " 'traitee',\n",
       " 'multifocal',\n",
       " 'stercorale',\n",
       " 'postoperatoire',\n",
       " 'nephropathie',\n",
       " 'volontaire',\n",
       " 'cerebraux',\n",
       " 'hauteur',\n",
       " 'piriforme',\n",
       " 'anemie,',\n",
       " 'osteoporose',\n",
       " 'etendue',\n",
       " 'chc',\n",
       " 'antecedents',\n",
       " 'traite',\n",
       " 'cardiocirculatoire',\n",
       " 'tetraplegie',\n",
       " 'dependance',\n",
       " 'carotide',\n",
       " 'baisse',\n",
       " 'arythmique',\n",
       " 'rythmique,',\n",
       " 'actif',\n",
       " 'paraplegie',\n",
       " 'defenestration',\n",
       " 'anticoagulants',\n",
       " 'asthenie',\n",
       " 'gastrique,',\n",
       " 'tvp',\n",
       " 'temporal',\n",
       " 'anorexie,',\n",
       " '2012',\n",
       " 'convulsive',\n",
       " 'pace',\n",
       " 'e',\n",
       " 'cuisse',\n",
       " 'ic',\n",
       " 'superieure',\n",
       " 'pneumothorax',\n",
       " 'recidivante',\n",
       " 'prostatite',\n",
       " 'mediastinale',\n",
       " 'trisomie',\n",
       " 'multi',\n",
       " 'bronches',\n",
       " 'pneumopathies',\n",
       " \"d'un\",\n",
       " 'localisation',\n",
       " 'atherome',\n",
       " 'oesophagien',\n",
       " 'transplantation',\n",
       " 'neuro-endocrine',\n",
       " 'volvulus',\n",
       " 'hypotension',\n",
       " 'droite,',\n",
       " 'fevg',\n",
       " 'obstacle',\n",
       " 'duodenal',\n",
       " 'aortique,',\n",
       " '15',\n",
       " '2015',\n",
       " 'triple',\n",
       " 'demato-ascitique',\n",
       " 'vieillissement',\n",
       " 'cognitifs,',\n",
       " 'carcinomatose',\n",
       " 'generalisation',\n",
       " 'pertrochanterienne',\n",
       " 'deficit',\n",
       " 'coronaropathie,',\n",
       " \"l'etat\",\n",
       " 'deterioration',\n",
       " 'bioprothese',\n",
       " 'infections',\n",
       " 'reanimation',\n",
       " 'sigmoidite',\n",
       " 'apres',\n",
       " 'ischemiques',\n",
       " 'pancreatique,',\n",
       " 'annees',\n",
       " 'canalaire',\n",
       " 'caecum',\n",
       " 'recidivant',\n",
       " 'pour',\n",
       " 'metas',\n",
       " 'ioniques',\n",
       " 'comateux',\n",
       " 'exacerbation',\n",
       " 'coma,',\n",
       " 'pelvienne',\n",
       " 'palliatifs,',\n",
       " 'dural',\n",
       " 'genou',\n",
       " 'flutter',\n",
       " 'ventilation',\n",
       " 'misere',\n",
       " 'cardio-ventilatoire',\n",
       " 'surrenaliennes',\n",
       " 'hematurie',\n",
       " 'inhalation,',\n",
       " 'sequelle',\n",
       " 'un',\n",
       " 'desaturation',\n",
       " 'plancher',\n",
       " 'basale',\n",
       " 'etranglee',\n",
       " 'adenome',\n",
       " 'hepato-renal',\n",
       " 'grande',\n",
       " 'hypoglycemie',\n",
       " 'connue',\n",
       " 'tracheotomie',\n",
       " 'maker',\n",
       " 'comitialite',\n",
       " 'confort',\n",
       " 'valvulaire,',\n",
       " 'congenitale',\n",
       " 'confusionnel',\n",
       " 'neurologiques',\n",
       " 'vih',\n",
       " 'necrosante',\n",
       " '?)',\n",
       " 'souffrance',\n",
       " 'deglutition,',\n",
       " 'generalisees',\n",
       " 'hospitalisation',\n",
       " '20',\n",
       " 'naissance',\n",
       " 'schizophrenie',\n",
       " 'iii',\n",
       " 'uterine',\n",
       " 'desequilibre',\n",
       " 'poids',\n",
       " 'cutanees',\n",
       " 'ra',\n",
       " 'hematomes',\n",
       " 'thrombo-embolique',\n",
       " 'anal',\n",
       " 'adenok',\n",
       " 'sevre',\n",
       " 'neutropenie',\n",
       " 'portale',\n",
       " '21',\n",
       " 'vegetatif',\n",
       " 'peritoneal',\n",
       " 'hyperthyroidie',\n",
       " 'sas',\n",
       " 'accidentelle',\n",
       " 'did,',\n",
       " 'multimetastasee',\n",
       " 'intra-cranienne',\n",
       " 'proteino-energetique',\n",
       " 'cerveau',\n",
       " 'alcoolisation',\n",
       " 'pericardique',\n",
       " 'dcd',\n",
       " \"d'alzheimer\",\n",
       " 'heures',\n",
       " 'generale',\n",
       " 'eg',\n",
       " 'waldenstrom',\n",
       " 'arterielle,',\n",
       " 'pleuro-pneumopathie',\n",
       " 'plaies',\n",
       " '2011',\n",
       " 'gastrostomie',\n",
       " 'conduction',\n",
       " 'hemorragique,',\n",
       " 'centrale',\n",
       " 'pnp',\n",
       " 'lam',\n",
       " 'intra-cerebrale',\n",
       " 'an',\n",
       " 'surinfectee',\n",
       " 'mediastinales',\n",
       " 'hemopathie',\n",
       " 'atrophie',\n",
       " '+++',\n",
       " 'bride',\n",
       " 'thyroide',\n",
       " 'confusion',\n",
       " 'retention',\n",
       " '++',\n",
       " 'mammaire,',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_processor.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(features):\n",
    "\n",
    "\n",
    "    txt = input_text_processor(features.pop('RawText'))\n",
    "    \n",
    "    labels = target_processor(features.pop('target'))\n",
    "    \n",
    "    return (txt,labels), labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(dataset_name, batch_size, preprocess = preprocess):\n",
    "\n",
    "    data = tf.data.experimental.make_csv_dataset(\n",
    "        path_data+'%s.csv' % dataset_name,\n",
    "        batch_size=batch_size,\n",
    "        column_names=COL_NAMES,\n",
    "        column_defaults=COL_TYPES,\n",
    "        header=True,\n",
    "        shuffle=True,\n",
    "        shuffle_buffer_size=20000,\n",
    "        sloppy=True,\n",
    "        prefetch_buffer_size=1,\n",
    "        use_quote_delim=True,\n",
    "        field_delim=';'\n",
    "\n",
    "    )\n",
    "\n",
    "    data = data.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    data = data.prefetch(buffer_size=1)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=((TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None)), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = input_fn(dataset_name = \"extrait500_corpus_train_code_target\",batch_size =32, preprocess  = preprocess)\n",
    "eval_ds = input_fn(dataset_name = \"extrait500_corpus_val_code_target\",batch_size =32, preprocess  = preprocess)\n",
    "\n",
    "\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(params):\n",
    "    lr_schedule = optimizer.LearningRateSchedule(\n",
    "        params['learning_rate'], params['hidden_size'],\n",
    "        params['learning_rate_warmup_steps']\n",
    "    )\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(\n",
    "        lr_schedule,\n",
    "        params['optimizer_adam_beta1'],\n",
    "        params[\"optimizer_adam_beta2\"],\n",
    "        epsilon=params[\"optimizer_adam_epsilon\"]\n",
    "    )\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_ds,eval_ds,params, model_dir):\n",
    "       \n",
    "    model = transformer.create_model(params, is_train=True)\n",
    "    opt = create_optimizer(params)\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(model=model, optimizer=opt)\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(model_dir)\n",
    "    if latest_checkpoint:\n",
    "        checkpoint.restore(latest_checkpoint)\n",
    "\n",
    "    board = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=model_dir, write_graph=False, update_freq=500\n",
    "    )\n",
    "    model.compile(opt)\n",
    "\n",
    "    model.fit(\n",
    "        x = train_ds,\n",
    "        epochs=5,\n",
    "        steps_per_epoch=10000,\n",
    "        verbose=1,\n",
    "        validation_data=eval_ds,\n",
    "        validation_steps=100,\n",
    "        callbacks=[board])\n",
    "    re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model_params.TINY_PARAMS\n",
    "params[\"batch_size\"] = params[\"default_batch_size\"] = 16\n",
    "params[\"use_synthetic_data\"] = True\n",
    "params[\"hidden_size\"] = 12\n",
    "params[\"num_hidden_layers\"] = 1\n",
    "params[\"filter_size\"] = 14\n",
    "params[\"num_heads\"] = 3\n",
    "params[\"extra_decode_length\"] = 2\n",
    "params[\"beam_size\"] = 3\n",
    "params[\"dtype\"] = tf.float32\n",
    "params['input_vocab_size'] = len(input_text_processor.get_vocabulary())\n",
    "params['vocab_size'] = len(target_processor.get_vocabulary())\n",
    "params['default_batch_size'] = 80*3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function official.nlp.transformer.model_params.<lambda>()>,\n",
       "            {'default_batch_size': 240,\n",
       "             'default_batch_size_tpu': 1024,\n",
       "             'max_length': 256,\n",
       "             'initializer_gain': 1.0,\n",
       "             'vocab_size': 34,\n",
       "             'hidden_size': 12,\n",
       "             'num_hidden_layers': 1,\n",
       "             'num_heads': 3,\n",
       "             'filter_size': 14,\n",
       "             'layer_postprocess_dropout': 0.1,\n",
       "             'attention_dropout': 0.1,\n",
       "             'relu_dropout': 0.1,\n",
       "             'label_smoothing': 0.1,\n",
       "             'learning_rate': 2.0,\n",
       "             'learning_rate_decay_rate': 1.0,\n",
       "             'learning_rate_warmup_steps': 16000,\n",
       "             'optimizer_adam_beta1': 0.9,\n",
       "             'optimizer_adam_beta2': 0.997,\n",
       "             'optimizer_adam_epsilon': 1e-09,\n",
       "             'extra_decode_length': 2,\n",
       "             'beam_size': 3,\n",
       "             'alpha': 0.6,\n",
       "             'use_tpu': False,\n",
       "             'static_batch': False,\n",
       "             'allow_ffn_pad': True,\n",
       "             'batch_size': 16,\n",
       "             'use_synthetic_data': True,\n",
       "             'dtype': tf.float32,\n",
       "             'input_vocab_size': 638})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\haris.medjahed\\AppData\\Roaming\\Python\\Python39\\site-packages\\official\\nlp\\transformer\\attention_layer.py:54: DenseEinsum.__init__ (from official.nlp.modeling.layers.dense_einsum) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "DenseEinsum is deprecated. Please use tf.keras.experimental.EinsumDense layer instead.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,optimizer\u001b[38;5;241m=\u001b[39m opt,metrics\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[0;32m     10\u001b[0m board \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(\n\u001b[0;32m     11\u001b[0m     log_dir\u001b[38;5;241m=\u001b[39mmodel_dir, write_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, update_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2452\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2449\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m-> 2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mgraph_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m   cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mgeneralize(cache_key)\n\u001b[0;32m   2709\u001b[0m   (args, kwargs) \u001b[38;5;241m=\u001b[39m cache_key\u001b[38;5;241m.\u001b[39m_placeholder_value()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2711\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                          graph_function)\n\u001b[0;32m   2715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2622\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2624\u001b[0m ]\n\u001b[0;32m   2625\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2626\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2638\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2639\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2641\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1116\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32mC:\\Users\\HARIS~2.MED\\AppData\\Local\\Temp\\__autograph_generated_filevpkrxogm.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1040\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1038\u001b[0m       run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1039\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1040\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1042\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1308\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1311\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1312\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2887\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2888\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3689\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 3689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1030\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m   \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:893\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m--> 893\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:537\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    507\u001b[0m   \u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03m  This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m   grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:590\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    588\u001b[0m var_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(var_list)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 590\u001b[0m   grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_valid_dtypes([\n\u001b[0;32m    593\u001b[0m     v \u001b[38;5;28;01mfor\u001b[39;00m g, v \u001b[38;5;129;01min\u001b[39;00m grads_and_vars\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m tf\u001b[38;5;241m.\u001b[39mresource\n\u001b[0;32m    595\u001b[0m ])\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:471\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    470\u001b[0m   \u001b[38;5;124;03m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m   grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1094\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1095\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1096\u001b[0m           output_gradients))\n\u001b[0;32m   1097\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1100\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1109\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\math_grad.py:266\u001b[0m, in \u001b[0;36m_MeanGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    263\u001b[0m   output_shape \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(op\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    264\u001b[0m   factor \u001b[38;5;241m=\u001b[39m _safe_shape_div(\n\u001b[0;32m    265\u001b[0m       math_ops\u001b[38;5;241m.\u001b[39mreduce_prod(input_shape), math_ops\u001b[38;5;241m.\u001b[39mreduce_prod(output_shape))\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmath_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruediv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msum_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmath_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msum_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1589\u001b[0m, in \u001b[0;36mtruediv\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmath.truediv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruediv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39mregister_binary_elementwise_api\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtruediv\u001b[39m(x, y, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1562\u001b[0m   \u001b[38;5;124;03m\"\"\"Divides x / y elementwise (using Python 3 division operator semantics).\u001b[39;00m\n\u001b[0;32m   1563\u001b[0m \n\u001b[0;32m   1564\u001b[0m \u001b[38;5;124;03m  NOTE: Prefer using the Tensor operator or tf.divide which obey Python\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1587\u001b[0m \u001b[38;5;124;03m    TypeError: If `x` and `y` have different dtypes.\u001b[39;00m\n\u001b[0;32m   1588\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1589\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_truediv_python3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1527\u001b[0m, in \u001b[0;36m_truediv_python3\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1525\u001b[0m   x \u001b[38;5;241m=\u001b[39m cast(x, dtype)\n\u001b[0;32m   1526\u001b[0m   y \u001b[38;5;241m=\u001b[39m cast(y, dtype)\n\u001b[1;32m-> 1527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal_div\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:7900\u001b[0m, in \u001b[0;36mreal_div\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   7898\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   7899\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 7900\u001b[0m   _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7901\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRealDiv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7902\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   7903\u001b[0m   _result \u001b[38;5;241m=\u001b[39m _dispatch\u001b[38;5;241m.\u001b[39mdispatch(\n\u001b[0;32m   7904\u001b[0m         real_div, (), \u001b[38;5;28mdict\u001b[39m(x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   7905\u001b[0m       )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:694\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    692\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    693\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:3754\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3751\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3752\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3753\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3754\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3755\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3756\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3757\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3758\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3759\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3760\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3761\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3763\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   3764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:2129\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2127\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m op_def \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2128\u001b[0m     op_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_get_op_def(node_def\u001b[38;5;241m.\u001b[39mop)\n\u001b[1;32m-> 2129\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2130\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2131\u001b[0m   name \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   2133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_traceback \u001b[38;5;241m=\u001b[39m tf_stack\u001b[38;5;241m.\u001b[39mextract_stack_for_node(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:1960\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1956\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(name),\n\u001b[0;32m   1957\u001b[0m                                          serialized)\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1960\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1963\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "drop_out_val = 0.3\n",
    "params['layer_postprocess_dropout'] = drop_out_val\n",
    "params['attention_dropout'] = drop_out_val\n",
    "params['relu_dropout'] = drop_out_val\n",
    "model_dir = path_model\n",
    "\n",
    "model = transformer.create_model(params, is_train=True)\n",
    "opt = create_optimizer(params)\n",
    "model.compile(opt)\n",
    "board = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=model_dir, write_graph=True, update_freq=500\n",
    ")\n",
    "model.fit(\n",
    "    x = train_ds,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=10000,\n",
    "    verbose=1,\n",
    "    validation_data=eval_ds,\n",
    "    validation_steps=100,\n",
    "    callbacks=[board]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle prédit en se servant des logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_SCALAR_UPRANKING_ON',\n",
       " '_TF_MODULE_IGNORED_PROPERTIES',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_activity_regularizer',\n",
       " '_add_trackable',\n",
       " '_add_trackable_child',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_assert_compile_was_called',\n",
       " '_assert_weights_created',\n",
       " '_auto_track_sub_layers',\n",
       " '_autocast',\n",
       " '_autographed_call',\n",
       " '_base_model_initialized',\n",
       " '_build_input_shape',\n",
       " '_call_accepts_kwargs',\n",
       " '_call_arg_was_passed',\n",
       " '_call_fn_arg_defaults',\n",
       " '_call_fn_arg_positions',\n",
       " '_call_fn_args',\n",
       " '_call_full_argspec',\n",
       " '_callable_losses',\n",
       " '_captured_weight_regularizer',\n",
       " '_cast_single_input',\n",
       " '_check_call_args',\n",
       " '_check_sample_weight_warning',\n",
       " '_checkpoint',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_cluster_coordinator',\n",
       " '_compile_was_called',\n",
       " '_compiled_trainable_state',\n",
       " '_compute_dtype',\n",
       " '_compute_dtype_object',\n",
       " '_compute_output_and_mask_jointly',\n",
       " '_compute_tensor_usage_count',\n",
       " '_configure_steps_per_execution',\n",
       " '_conform_to_reference_input',\n",
       " '_dedup_weights',\n",
       " '_default_training_arg',\n",
       " '_deferred_dependencies',\n",
       " '_delete_tracking',\n",
       " '_deserialization_dependencies',\n",
       " '_deserialize_from_proto',\n",
       " '_distribution_strategy',\n",
       " '_dtype',\n",
       " '_dtype_policy',\n",
       " '_dynamic',\n",
       " '_eager_losses',\n",
       " '_enable_dict_to_input_mapping',\n",
       " '_expects_mask_arg',\n",
       " '_expects_training_arg',\n",
       " '_export_to_saved_model_graph',\n",
       " '_feed_input_names',\n",
       " '_feed_input_shapes',\n",
       " '_feed_inputs',\n",
       " '_flatten',\n",
       " '_flatten_layers',\n",
       " '_flatten_modules',\n",
       " '_flatten_to_reference_inputs',\n",
       " '_functional_construction_call',\n",
       " '_gather_children_attribute',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_call_arg_value',\n",
       " '_get_callback_model',\n",
       " '_get_cell_name',\n",
       " '_get_compile_args',\n",
       " '_get_existing_metric',\n",
       " '_get_input_masks',\n",
       " '_get_legacy_saved_model_children',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_optimizer',\n",
       " '_get_save_spec',\n",
       " '_get_trainable_state',\n",
       " '_get_unnested_name_scope',\n",
       " '_graph_network_add_loss',\n",
       " '_graph_network_add_metric',\n",
       " '_handle_activity_regularization',\n",
       " '_handle_deferred_dependencies',\n",
       " '_handle_deferred_layer_dependencies',\n",
       " '_handle_weight_regularization',\n",
       " '_in_multi_worker_mode',\n",
       " '_inbound_nodes',\n",
       " '_inbound_nodes_value',\n",
       " '_infer_output_signature',\n",
       " '_init_batch_counters',\n",
       " '_init_call_fn_args',\n",
       " '_init_graph_network',\n",
       " '_init_set_name',\n",
       " '_initial_weights',\n",
       " '_input_coordinates',\n",
       " '_input_layers',\n",
       " '_input_spec',\n",
       " '_insert_layers',\n",
       " '_instrument_layer_creation',\n",
       " '_instrumented_keras_api',\n",
       " '_instrumented_keras_layer_class',\n",
       " '_instrumented_keras_model_class',\n",
       " '_is_compiled',\n",
       " '_is_graph_network',\n",
       " '_is_layer',\n",
       " '_is_model_for_instrumentation',\n",
       " '_jit_compile',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_keras_tensor_symbolic_call',\n",
       " '_layer_call_argspecs',\n",
       " '_layer_checkpoint_dependencies',\n",
       " '_layout_map',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_losses',\n",
       " '_map_resources',\n",
       " '_maybe_build',\n",
       " '_maybe_cast_inputs',\n",
       " '_maybe_create_attribute',\n",
       " '_maybe_initialize_trackable',\n",
       " '_maybe_load_initial_epoch_from_ckpt',\n",
       " '_maybe_load_initial_step_from_ckpt',\n",
       " '_metrics',\n",
       " '_metrics_lock',\n",
       " '_must_restore_from_config',\n",
       " '_name',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_name_scope',\n",
       " '_name_scope_on_declaration',\n",
       " '_nested_inputs',\n",
       " '_nested_outputs',\n",
       " '_network_nodes',\n",
       " '_no_dependency',\n",
       " '_nodes_by_depth',\n",
       " '_non_trainable_weights',\n",
       " '_obj_reference_counts',\n",
       " '_obj_reference_counts_dict',\n",
       " '_object_identifier',\n",
       " '_outbound_nodes',\n",
       " '_outbound_nodes_value',\n",
       " '_output_coordinates',\n",
       " '_output_layers',\n",
       " '_output_mask_cache',\n",
       " '_output_shape_cache',\n",
       " '_output_tensor_cache',\n",
       " '_predict_counter',\n",
       " '_preload_simple_restoration',\n",
       " '_preserve_input_structure_in_config',\n",
       " '_reset_compile_cache',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_restore_from_tensors',\n",
       " '_run_eagerly',\n",
       " '_run_internal_graph',\n",
       " '_saved_model_arg_spec',\n",
       " '_saved_model_inputs_spec',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_tracked_trackables',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_to_proto',\n",
       " '_serialize_to_tensors',\n",
       " '_set_call_arg_value',\n",
       " '_set_connectivity_metadata',\n",
       " '_set_dtype_policy',\n",
       " '_set_inputs',\n",
       " '_set_mask_keras_history_checked',\n",
       " '_set_mask_metadata',\n",
       " '_set_output_names',\n",
       " '_set_save_spec',\n",
       " '_set_trainable_state',\n",
       " '_set_training_mode',\n",
       " '_setattr_tracking',\n",
       " '_should_cast_single_input',\n",
       " '_should_compute_mask',\n",
       " '_should_eval',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_split_out_first_arg',\n",
       " '_stateful',\n",
       " '_steps_per_execution',\n",
       " '_supports_masking',\n",
       " '_tensor_usage_count',\n",
       " '_test_counter',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_thread_local',\n",
       " '_track_trackable',\n",
       " '_trackable_children',\n",
       " '_trackable_saved_model_saver',\n",
       " '_tracking_metadata',\n",
       " '_train_counter',\n",
       " '_trainable',\n",
       " '_trainable_weights',\n",
       " '_training_state',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_undeduplicated_weights',\n",
       " '_update_uid',\n",
       " '_updated_config',\n",
       " '_updates',\n",
       " '_use_input_spec_as_call_signature',\n",
       " '_validate_compile',\n",
       " '_validate_graph_inputs_and_outputs',\n",
       " '_validate_target_and_loss',\n",
       " 'activity_regularizer',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compile',\n",
       " 'compiled_loss',\n",
       " 'compiled_metrics',\n",
       " 'compute_dtype',\n",
       " 'compute_loss',\n",
       " 'compute_mask',\n",
       " 'compute_metrics',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_signature',\n",
       " 'count_params',\n",
       " 'distribute_strategy',\n",
       " 'dtype',\n",
       " 'dtype_policy',\n",
       " 'dynamic',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'finalize_state',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_layer',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_weights',\n",
       " 'history',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_names',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'inputs',\n",
       " 'layers',\n",
       " 'load_weights',\n",
       " 'loss',\n",
       " 'losses',\n",
       " 'make_predict_function',\n",
       " 'make_test_function',\n",
       " 'make_train_function',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'name',\n",
       " 'name_scope',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'optimizer',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_names',\n",
       " 'output_shape',\n",
       " 'outputs',\n",
       " 'predict',\n",
       " 'predict_function',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'predict_step',\n",
       " 'reset_metrics',\n",
       " 'reset_states',\n",
       " 'run_eagerly',\n",
       " 'save',\n",
       " 'save_spec',\n",
       " 'save_weights',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'stop_training',\n",
       " 'submodules',\n",
       " 'summary',\n",
       " 'supports_masking',\n",
       " 'test_function',\n",
       " 'test_on_batch',\n",
       " 'test_step',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'train_function',\n",
       " 'train_on_batch',\n",
       " 'train_step',\n",
       " 'train_tf_function',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'variable_dtype',\n",
       " 'variables',\n",
       " 'weights',\n",
       " 'with_name_scope']"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"Model_poids/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\haris.medjahed\\AppData\\Roaming\\Python\\Python39\\site-packages\\official\\nlp\\transformer\\attention_layer.py:54: DenseEinsum.__init__ (from official.nlp.modeling.layers.dense_einsum) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "DenseEinsum is deprecated. Please use tf.keras.experimental.EinsumDense layer instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x235bb8c9eb0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_test = transformer.create_model(params, is_train=False)\n",
    "Model_test.load_weights(\"Model_poids/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x24149c9fdf0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = input_fn(dataset_name = \"extrait500_corpus_train_code_target\",batch_size =32, preprocess  = preprocess\n",
    "                  )\n",
    "iterator = iter(dataset)\n",
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/extrait500_corpus_test_code_target.csv\", encoding='utf-8', sep=\";\")\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 5), dtype=int64, numpy=\n",
       "array([[ 2, 11,  3,  0,  0],\n",
       "       [ 2, 27,  3,  0,  0],\n",
       "       [ 2,  9, 25,  3,  0],\n",
       "       [ 2,  7,  8, 28,  3],\n",
       "       [ 2, 21, 20,  3,  0],\n",
       "       [ 2,  4, 17,  3,  0],\n",
       "       [ 2, 31, 30,  3,  0],\n",
       "       [ 2,  4, 15,  3,  0],\n",
       "       [ 2,  5, 10,  3,  0],\n",
       "       [ 2,  4, 17,  3,  0],\n",
       "       [ 2,  9, 12,  3,  0],\n",
       "       [ 2, 11,  3,  0,  0],\n",
       "       [ 2,  7,  6, 13,  3],\n",
       "       [ 2,  4, 15,  3,  0],\n",
       "       [ 2, 24,  3,  0,  0],\n",
       "       [ 2, 16,  3,  0,  0],\n",
       "       [ 2,  7,  6,  3,  0],\n",
       "       [ 2, 11, 18,  3,  0],\n",
       "       [ 2,  5, 10,  3,  0],\n",
       "       [ 2,  9, 12,  3,  0],\n",
       "       [ 2,  7,  8,  3,  0],\n",
       "       [ 2, 11,  3,  0,  0],\n",
       "       [ 2, 33, 32,  3,  0],\n",
       "       [ 2, 11,  3,  0,  0],\n",
       "       [ 2, 23, 22,  3,  0],\n",
       "       [ 2,  7,  8,  3,  0],\n",
       "       [ 2, 23, 22,  3,  0],\n",
       "       [ 2,  9, 12,  3,  0],\n",
       "       [ 2,  7,  6,  3,  0],\n",
       "       [ 2, 31, 30,  3,  0],\n",
       "       [ 2, 16,  3,  0,  0],\n",
       "       [ 2,  4, 17,  3,  0]], dtype=int64)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = iterator.get_next()\n",
    "a[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] pneumopathie [END]  \n",
      "[START] cachexie [END]  \n",
      "[START] defaillance polyviscerale [END] \n",
      "[START] insuffisance cardiaque terminale [END]\n",
      "[START] cardiopathie ischemique [END] \n",
      "[START] arret cardiorespiratoire [END] \n",
      "[START] embolie pulmonaire [END] \n",
      "[START] arret cardio-respiratoire [END] \n",
      "[START] choc septique [END] \n",
      "[START] arret cardiorespiratoire [END] \n",
      "[START] defaillance multiviscerale [END] \n",
      "[START] pneumopathie [END]  \n",
      "[START] insuffisance respiratoire aigu [END]\n",
      "[START] arret cardio respiratoire [END]\n",
      "[START] hta [END]  \n",
      "[START] survenue d&aposun coma [END]\n",
      "[START] insuffisance respiratoire [END] \n",
      "[START] pneumopathie d&aposinhalation [END] \n",
      "[START] choc septique [END] \n",
      "[START] defaillance multiviscerale [END] \n",
      "[START] insuffisance cardiaque [END] \n",
      "[START] pneumopathie [END]  \n",
      "[START] carcinose peritoneale [END] \n",
      "[START] pneumopathie [END]  \n",
      "[START] infarctus du myocarde [END]\n",
      "[START] insuffisance cardiaque [END] \n",
      "[START] infarctus du myocarde [END]\n",
      "[START] defaillance multi viscerale [END]\n",
      "[START] insuffisance respiratoire [END] \n",
      "[START] embolie pulmonaire [END] \n",
      "[START] coma [END]  \n",
      "[START] arret cardiorespiratoire [END] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(a[0][0])):\n",
    "    vocab = input_text_processor.get_vocabulary()\n",
    "    print(\" \".join([vocab[each] for each in tf.squeeze(a[0][0][i])])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2, 11,  3,  3,  3,  3,  3],\n",
       "        [ 2, 27,  3,  3,  3,  3,  3],\n",
       "        [ 2,  9, 12,  3,  3,  3,  3],\n",
       "        [ 2,  7,  8,  3,  3,  3,  3],\n",
       "        [ 2, 21, 20,  3,  3,  3,  3],\n",
       "        [ 2,  4, 17,  3,  3,  3,  3],\n",
       "        [ 2, 31, 30,  3,  3,  3,  3],\n",
       "        [ 2,  4, 15,  3,  3,  3,  3],\n",
       "        [ 2,  5, 10,  3,  3,  3,  3],\n",
       "        [ 2,  4, 17,  3,  3,  3,  3],\n",
       "        [ 2,  9, 12,  3,  3,  3,  3],\n",
       "        [ 2, 11,  3,  3,  3,  3,  3],\n",
       "        [ 2,  7,  6,  3,  3,  3,  3],\n",
       "        [ 2,  4, 17,  3,  3,  3,  3],\n",
       "        [ 2, 24,  3,  3,  3,  3,  3],\n",
       "        [ 2, 16,  3,  3,  3,  3,  3],\n",
       "        [ 2,  7,  6,  3,  3,  3,  3],\n",
       "        [ 2, 11, 18,  3,  3,  3,  3],\n",
       "        [ 2,  5, 10,  3,  3,  3,  3],\n",
       "        [ 2,  9, 12,  3,  3,  3,  3],\n",
       "        [ 2,  7,  8,  3,  3,  3,  3],\n",
       "        [ 2, 11,  3,  3,  3,  3,  3],\n",
       "        [ 2, 33, 32,  3,  3,  3,  3],\n",
       "        [ 2, 11,  3,  3,  3,  3,  3],\n",
       "        [ 2, 23, 22,  3,  3,  3,  3],\n",
       "        [ 2,  7,  8,  3,  3,  3,  3],\n",
       "        [ 2, 23, 22,  3,  3,  3,  3],\n",
       "        [ 2,  9, 12,  3,  3,  3,  3],\n",
       "        [ 2,  7,  6,  3,  3,  3,  3],\n",
       "        [ 2, 31, 30,  3,  3,  3,  3],\n",
       "        [ 2, 16,  3,  3,  3,  3,  3],\n",
       "        [ 2,  4, 17,  3,  3,  3,  3]]),\n",
       " array([-0.4903965 , -1.0148519 , -0.9625943 , -0.44645345, -0.77421784,\n",
       "        -0.80942976, -1.1162871 , -1.1359591 , -0.42359626, -0.80942976,\n",
       "        -0.5248909 , -0.4903965 , -0.74648726, -1.0492655 , -0.93214095,\n",
       "        -1.0998135 , -0.4789579 , -0.7628627 , -0.42359626, -0.5248909 ,\n",
       "        -0.42891133, -0.4903965 , -1.7166142 , -0.4903965 , -0.97102165,\n",
       "        -0.42891133, -0.97102165, -0.55927   , -0.4789579 , -1.1162871 ,\n",
       "        -0.44496548, -0.80942976], dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Model_test.predict(a[0][0])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(test[0])):\n",
    "    vocab = target_processor.get_vocabulary()\n",
    "    print(\" \".join([vocab[each] for each in tf.squeeze(test[0][i])])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a[1])):\n",
    "    vocab = target_processor.get_vocabulary()\n",
    "    print(\" \".join([vocab[each] for each in tf.squeeze(a[1][i])])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def precision(prediction, labels):\n",
    "    labels = labels.numpy()\n",
    "    prediction = np.where(prediction==2,0,prediction)\n",
    "    prediction = np.where(prediction==3,0,prediction)\n",
    "    labels = np.where(labels==2,0,labels)\n",
    "    labels = np.where(labels==3,0,labels)\n",
    "    size = np.shape(labels)[1]\n",
    "    if np.shape(prediction)[1]<size: #On ajoute des zeros si la prediction n'est pas assez longue pour correspondre aux labels\n",
    "        result = np.zeros(labels.shape)\n",
    "        result[:prediction.shape[0],:prediction.shape[1]] = prediction\n",
    "        prediction = result\n",
    "    y_pred = prediction[:,:size] #On réduit la prédiction à la taille des labels sinon, et on exclut le [START]\n",
    "    precision = 0\n",
    "    for i in range(labels.shape[0]):\n",
    "        k = 1\n",
    "        for j in range(size):\n",
    "            if labels[i,k] != 0 :\n",
    "                k+=1\n",
    "        print(\"La précision de la phrase\", i+1,\"est de :\", accuracy_score(labels[i,1:k], y_pred[i,1:k]))\n",
    "        precision += accuracy_score(labels[i,1:k], y_pred[i,1:k])\n",
    "    precision_moyenne = precision/labels.shape[0]\n",
    "    print(\"La précision moyenne du modèle sur ce batch est de : \", precision_moyenne)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision(test[0],a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from official.nlp.transformer import metrics as t_metrics\n",
    "\n",
    "\n",
    "def isin(padded_outputs,padded_labels):\n",
    "    \"\"\"Percentage of time logits contains labels on non-0s.\"\"\"\n",
    "    with tf.name_scope(\"isin\"):\n",
    "        tile_multiple = tf.shape(padded_labels)[-1]\n",
    "        tiled_outputs = tf.tile(tf.expand_dims(padded_outputs, axis=-1), multiples=[1, 1, tile_multiple])\n",
    "        tiled_labels = tf.reshape(tf.tile(padded_labels, multiples=[1, tile_multiple]), [-1, tile_multiple, tile_multiple])\n",
    "        equal = tf.equal(tiled_outputs, tiled_labels)\n",
    "        any = tf.reduce_any(equal, axis=-1)\n",
    "        return any\n",
    "\n",
    "\n",
    "def true_false_positives(logits, labels):\n",
    "    size = np.shape(labels)[1]\n",
    "    logits = logits[:,:size]\n",
    "    labels = labels[:,:size]\n",
    "    logits = np.where(logits==2,0,logits)\n",
    "    logits = np.where(logits==3,0,logits)\n",
    "    labels = np.where(labels==2,0,labels)\n",
    "    labels = np.where(labels==3,0,labels)\n",
    "    padded_outputs = tf.cast(logits, tf.int32)\n",
    "    padded_labels = tf.cast(labels, tf.int32)\n",
    "\n",
    "    weights_outputs = tf.logical_and(tf.not_equal(padded_outputs, 0), tf.not_equal(padded_outputs, 1))\n",
    "    weights_labels = tf.logical_and(tf.not_equal(padded_labels, 0), tf.not_equal(padded_labels, 1))\n",
    "    \n",
    "    true_p = tf.logical_and(isin(padded_labels, padded_outputs), weights_outputs)\n",
    "    out_in_lab = tf.logical_or(isin(padded_labels, padded_outputs), tf.logical_not(weights_outputs))\n",
    "    lab_in_out = tf.logical_or(isin(padded_labels, padded_outputs), tf.logical_not(weights_labels))\n",
    "    \n",
    "    true_positives = tf.cast(true_p, tf.float32)\n",
    "    false_positives = tf.cast(tf.logical_not(out_in_lab), tf.float32)\n",
    "    false_negatives = tf.cast(tf.logical_not(lab_in_out), tf.float32)\n",
    "\n",
    "    return tf.reduce_sum(true_positives), tf.reduce_sum(false_positives), tf.reduce_sum(false_negatives)\n",
    "\n",
    "\n",
    "def my_metrics(logits, labels):\n",
    "\n",
    "    true_positives, false_positives, false_negatives = true_false_positives(logits, labels)\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f_measure = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    metrics = (tf.keras.metrics.Mean)\n",
    "\n",
    "    return precision, recall, f_measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m true_false_positives(np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtest\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]]),np\u001b[38;5;241m.\u001b[39marray([a[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "true_false_positives(np.array([test[0][1]]),np.array([a[1][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = my_metrics(test[0],a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:446\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    438\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    439\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    441\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124m    from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124m    np_config.enable_numpy_behavior()\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m--> 446\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "z[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.931034505367279"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 5 + float(z[1])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processor = preprocessing.TextVectorization(\n",
    "    standardize=None,\n",
    "    max_tokens=None)\n",
    "\n",
    "data_test = pd.read_csv(\"data/extrait500_corpus_test_code_target.csv\", encoding='utf-8', sep=\";\")\n",
    "test_processor.adapt(data_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulaire_test = test_processor.get_vocabulary()\n",
    "for i in range(len(vocabulaire_test)):\n",
    "    vocabulaire_test[i] = [vocabulaire_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"data/vocabulaire_test.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(vocabulaire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess1(features):\n",
    "\n",
    "\n",
    "    txt = input_text_processor(features.pop('Dico'))\n",
    "    \n",
    "    return txt\n",
    "\n",
    "\n",
    "def input_fn1(dataset_name, batch_size, preprocess = preprocess):\n",
    "\n",
    "    data = tf.data.experimental.make_csv_dataset(\n",
    "        path_data+'%s.csv' % dataset_name,\n",
    "        batch_size=batch_size,\n",
    "        column_names=['Dico'],\n",
    "        column_defaults=['a'],\n",
    "        header=True,\n",
    "        shuffle=False,\n",
    "        shuffle_buffer_size=20000,\n",
    "        sloppy=True,\n",
    "        prefetch_buffer_size=1,\n",
    "        use_quote_delim=True,\n",
    "        field_delim=';'\n",
    "\n",
    "    )\n",
    "\n",
    "    data = data.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    data = data.prefetch(buffer_size=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = input_fn1(dataset_name = \"vocabulaire_test\",batch_size =31, preprocess  = preprocess1\n",
    "                  )\n",
    "iterator = iter(dataset1)\n",
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = Model_test.predict(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(test2[0])):\n",
    "    vocab = target_processor.get_vocabulary()\n",
    "    print(i)\n",
    "    print(\" \".join([vocab[each] for each in tf.squeeze(test[0][i])])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_processor.get_vocabulary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
